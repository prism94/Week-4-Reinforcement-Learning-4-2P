{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EJvZFToZeV_x"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DXIy0e0DemmX"
   },
   "outputs": [],
   "source": [
    "env = gym.make('Blackjack-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ONyh1MjR7tMq"
   },
   "outputs": [],
   "source": [
    "def get_probs(Q_s, epsilon, nA): #nA is no. of actions in the action space\n",
    "    # obtains the action probabilities corresponding to epsilon-greedy policy\n",
    "    policy_s = np.ones(nA) * epsilon / nA\n",
    "    best_a = np.argmax(Q_s)\n",
    "    policy_s[best_a] = 1 - epsilon + (epsilon / nA)\n",
    "    return policy_s\n",
    "  \n",
    "''' \n",
    "Now we will use this get_probs func in generating the episode. \n",
    "Note that we are no longer using the stochastic policy we started with, instead building upon it in an epsilon greedy way.\n",
    "'''\n",
    "def generate_episode_from_Q(env, Q, epsilon, nA):\n",
    "    # generates an episode from following the epsilon-greedy policy\n",
    "    episode = []\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        action = np.random.choice(np.arange(nA), p=get_probs(Q[state], epsilon, nA)) \\\n",
    "                                    if state in Q else env.action_space.sample()\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        episode.append((state, action, reward))\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    return episode\n",
    "\n",
    "''' \n",
    "Finally Q values are approximated by taking average of corresponding returns.\n",
    "But instead we can write it using incremental mean and constant alpha.\n",
    "As we are using constant alpha we need not keep a track of N-table, ie how many times we visited that state.\n",
    "''' \n",
    "\n",
    "def update_Q(env, episode, Q, alpha, gamma):\n",
    "    # updates the action-value function estimate using the most recent episode \n",
    "    states, actions, rewards = zip(*episode)\n",
    "    # prepare for discounting\n",
    "    discounts = np.array([gamma**i for i in range(len(rewards)+1)])\n",
    "    for i, state in enumerate(states):\n",
    "        old_Q = Q[state][actions[i]] \n",
    "        Q[state][actions[i]] = old_Q + alpha*(sum(rewards[i:]*discounts[:-(1+i)]) - old_Q)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zgaIRefme4z_"
   },
   "outputs": [],
   "source": [
    "def ori_policy_implementation(Q, policy, iter):\n",
    "    rewards = []\n",
    "    nA=env.action_space.n\n",
    "    for i_episode in range(iter):\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            action = np.random.choice(np.arange(nA), p=get_probs(Q[state], 0, nA)) \\\n",
    "                                        if state in Q else env.action_space.sample()\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            state = next_state\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uqFDeMpo_dPc"
   },
   "outputs": [],
   "source": [
    "def mc_control(env, num_episodes, alpha, gamma=1.0, eps_start=1.0, eps_decay=.99999, eps_min=0.05):\n",
    "    nA = env.action_space.n\n",
    "    # initialize empty dictionary of arrays\n",
    "    Q = defaultdict(lambda: np.zeros(nA))\n",
    "    epsilon = eps_start\n",
    "\n",
    "    ep_rewards = []\n",
    "    avg = 0\n",
    "    count = 0\n",
    "\n",
    "    # loop over episodes\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        # monitor progress\n",
    "        if i_episode % 1000 == 0:\n",
    "            print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "        # set the value of epsilon\n",
    "        epsilon = max(epsilon*eps_decay, eps_min)\n",
    "        # generate an episode by following epsilon-greedy policy\n",
    "        episode = generate_episode_from_Q(env, Q, epsilon, nA)\n",
    "        # update the action-value function estimate using the episode\n",
    "        Q = update_Q(env, episode, Q, alpha, gamma)\n",
    "        # determine the policy corresponding to the final action-value function estimate\n",
    "        policy = dict((k,np.argmax(v)) for k, v in Q.items())\n",
    "        \n",
    "        ep_reward = ori_policy_implementation(Q, policy, 5)\n",
    "\n",
    "        if len(ep_reward) > 0:\n",
    "            count += 1\n",
    "            avg += (1/count)*(np.array(ep_reward).mean() - avg)\n",
    "            ep_rewards.append(avg)\n",
    "        else:\n",
    "            ep_rewards.append(avg)\n",
    "            \n",
    "    \n",
    "    return policy, Q, ep_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9y81SXAuqEXi"
   },
   "outputs": [],
   "source": [
    "def episodes_off_policy(env):\n",
    "\n",
    "    nA = env.action_space.n\n",
    "    probs = np.array([1/nA for _ in range(nA)])\n",
    "\n",
    "    e = []\n",
    "    s = env.reset()\n",
    "\n",
    "    while True:\n",
    "        action = np.random.choice(np.arange(nA), p = probs)\n",
    "        \n",
    "        next, r, d, _ = env.step(action)\n",
    "        e.append((s, action, r))\n",
    "        s = next\n",
    "        if d:\n",
    "          break\n",
    "    \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8WdKU9Z7FutE"
   },
   "outputs": [],
   "source": [
    "def off_policy_implementation(Q, policy, iter):\n",
    "    nA=env.action_space.n\n",
    "    r = []\n",
    "    for i_episode in range(iter):\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            if state in policy:\n",
    "                action = policy[state]\n",
    "            else:\n",
    "                action = np.random.choice(np.arange(nA))\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        r.append(reward)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "53xIsgTkeBeA"
   },
   "outputs": [],
   "source": [
    "def mc_control_off_policy(env, num_episodes, gamma=1.0, eps_start=1.0, eps_decay=.99999, eps_min=0.05):\n",
    "\n",
    "    nA = env.action_space.n\n",
    "    Q = {}\n",
    "    C = {}\n",
    "    epsilon = eps_start\n",
    "\n",
    "    rewards_list = []\n",
    "    avg = 0\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"\\rEpisode {}/{}.\".format(i, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        episode = episodes_off_policy(env)\n",
    "        \n",
    "        W = 1\n",
    "        G = 0\n",
    "\n",
    "        for ep in episode:\n",
    "            state, action, reward = ep\n",
    "\n",
    "            G = gamma*G + reward\n",
    "\n",
    "            if state not in Q:\n",
    "                Q[state] = np.zeros(nA)\n",
    "                C[state] = np.zeros(nA)\n",
    "\n",
    "            C[state][action] += W\n",
    "            Q[state][action] += (W/C[state][action])*(G - Q[state][action])\n",
    "\n",
    "            pol = np.argmax(Q[state])\n",
    "\n",
    "            if pol != action:\n",
    "                break\n",
    "\n",
    "            W += W*(1/(1/nA))\n",
    "        policy = dict((k,np.argmax(v)) for k, v in Q.items())\n",
    "        rewards = off_policy_implementation(Q, policy, 5)\n",
    "        rewards_mean = np.array(rewards).mean()\n",
    "        avg += (1/(i+1))*(rewards_mean - avg)\n",
    "        rewards_list.append(avg)\n",
    "    \n",
    "    return policy, Q, rewards_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nq-vVGzIjM8A",
    "outputId": "05c13dbe-8a6d-4c7d-db3c-8bb535ae80a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500000/500000."
     ]
    }
   ],
   "source": [
    "policy, Q, ori_rewards = mc_control(env, 500000, 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2y-KLphH8xIN",
    "outputId": "6866ef66-af0a-42a5-e660-02fac9262e1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 499000/500000."
     ]
    }
   ],
   "source": [
    "policy, Q, rewards_off_policy = mc_control_off_policy(env, 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "vWnT2Mv9edgB",
    "outputId": "ed9e6234-80c3-4fc1-c067-3f9d32c3c0b5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(rewards_off_policy, label = 'Off Policy')\n",
    "plt.plot(ori_rewards, label = 'Original')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-2P.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
